%% Clear everything
clear all
close all

%% Read the numerical train dataset for Naive Bayes Model Selection
nb_ms=readtable('trainNum.csv');

%% specify that the last column is ordinal categorical data
avalues={'unacc','acc','good','vgood'};
nb_ms.acceptability=categorical(nb_ms.acceptability,avalues,'Ordinal',true);

%% Summarize
summary(nb_ms);
tabulate(nb_ms.acceptability)

%% Examine if any of the variables are highly correlated. 
CM=corrcoef(table2array(nb_ms(:,1:6)));
heatmap(CM);

% we can see none of the independent variables are highly correlated, so we
% can include them all. 

%% Hyper parameter optimization for fincnb
% this optimization can only optimize normal or kernel distributions. So we
% are going to pick the the most optimal values from it and compare it with
% a model which uses the multivariate multinomial distributions. 

%One of the variables that we are also going to explore is the number of
%folds

num_folds=[];
best_dist=[];
best_width=[];
best_kernel=[];

for f = 5:10

        X=nb_ms(:,1:6);
        Y=nb_ms(:,7);
        prior = [0.6999 0.2227 0.0398 0.0376];
        class_names={'unacc','acc','good','vgood'};
        rng(1);

        Mdl = fitcnb(X,Y,...
            'ClassNames',class_names,...
            'Prior',prior,...
            'OptimizeHyperparameters','all',...
            'HyperparameterOptimizationOptions',struct('AcquisitionFunctionName','expected-improvement-plus',...
            'Kfold',f));

        % Get the best hyper parameters
        BestDist=Mdl.ModelParameters.DistributionNames;
        BestWidth=Mdl.ModelParameters.Width;
        BestKernelType=Mdl.ModelParameters.Kernel;
        
        %save the results
        num_folds=[num_folds;f];
        best_dist=[best_dist;cellstr(BestDist)];
        best_width=[best_width;BestWidth];
        best_kernel=[best_kernel;cellstr(BestKernelType)];
end


%% Check the results
num_folds=array2table(num_folds);
best_dist=array2table(best_dist);
best_width=array2table(best_width);
best_kernel=array2table(best_kernel);

normal_kernel_best_params=[num_folds best_dist best_width best_kernel];

%% We can see that for each CV type, we get slightly different results:
% Let's add the accuracy and cross entropy to each of the models above

accuracy=[];
cross_entropy=[];
time=[];

for m=1:6
    ac_cv=[];
    ce_cv=[];
    target_all=[];
    predictions_all=[];
    prior = [0.6999 0.2227 0.0398 0.0376];
    class_names={'unacc','acc','good','vgood'};
    distributions=char(table2cell(normal_kernel_best_params(m,2)));
    w=table2array(normal_kernel_best_params(m,3));
    ktype=char(table2cell(normal_kernel_best_params(m,4)));
    num_folds = table2array(normal_kernel_best_params(m,1));
    training_err = zeros(num_folds,1);
    
    rng(1);
    c = cvpartition(nb_ms.acceptability,'KFold',num_folds);
    startt=cputime;
    for fold = 1:num_folds
            %get the train and validation sets
             train = nb_ms(c.training(fold), :);   
             val = nb_ms(c.test(fold), :);

             %split them into X and Y arrays
             Xtr=table2array(train(:,1:6));
             Ytr=table2array(train(:,7));

             Xv=table2array(val(:,1:6));
             Yv=table2array(val(:,7));

             % Train a model
                Mdl = fitcnb(Xtr,Ytr,...
                    'ClassNames',class_names,...
                    'Prior',prior,...
                    'DistributionNames',distributions,...
                    'Width',w,...
                    'Kernel',ktype);

            % Predict Results
            [label,Posterior,Cost] = predict(Mdl,Xv);

            % Store the results against their targets
            target_all=[target_all; Yv];
            predictions_all=[predictions_all;label];

            % Evaluate Model
            [ac, ce]=performance_metrics(Mdl, Xv,Yv, Posterior);
            ac_cv=[ac_cv;ac];
            ce_cv=[ce_cv;ce];
    end
        endt=cputime;
        kernel_time=endt-startt;
        % Get the mean performance metrics for all the folds
        kernel_mean_ac_cv=mean(ac_cv);
        kernel_mean_ce_cv=mean(ce_cv);

        kernel_mean_ac_cv;
        kernel_mean_ce_cv;
        
        %Save the results
        accuracy=[accuracy;kernel_mean_ac_cv];
        cross_entropy=[cross_entropy;kernel_mean_ce_cv];
        time=[time;kernel_time];
    
end;
    

%% Add the results to the original table
accuracy=array2table(accuracy);
cross_entropy=array2table(cross_entropy);
time=array2table(time);

normal_kernel_best_params=[normal_kernel_best_params accuracy cross_entropy time];

%% Compare the previous results with the 'mvmn' distribution across the same fold types
%% 1) Cross Validation with 'mvmn' distribution of variables
% set out all the variables

num_folds=[];
accuracy=[];
cross_entropy=[];
best_dist=[];
time=[];
best_kernel=[];

for f=5:10
    ac_cv=[];
    ce_cv=[];
    target_all=[];
    predictions_all=[];
    prior = [0.6999 0.2227 0.0398 0.0376];
    class_names={'unacc','acc','good','vgood'};
    distributions='mvmn';
    num_folds = f;
    training_err = zeros(num_folds,1);

    rng(1);
    c = cvpartition(nb_ms.acceptability,'KFold',num_folds);

    startt=cputime;
    for fold = 1:f
        %get the train and validation sets
         train = nb_ms(c.training(fold), :);   
         val = nb_ms(c.test(fold), :);

         %split them into X and Y arrays
         Xtr=table2array(train(:,1:6));
         Ytr=table2array(train(:,7));

         Xv=table2array(val(:,1:6));
         Yv=table2array(val(:,7));

         % Train a model
            Mdl = fitcnb(Xtr,Ytr,...
                'ClassNames',class_names,...  
                'Prior',prior,...
                'DistributionNames',distributions);
                %'Width',w,...
                %'Kernel',ktype);

        % Predict Results
        [label,Posterior,Cost] = predict(Mdl,Xv);

        % Store the results against their targets
        target_all=[target_all; Yv];
        predictions_all=[predictions_all;label];

        % Evaluate Model
        [ac, ce]=performance_metrics(Mdl, Xv,Yv, Posterior);
        ac_cv=[ac_cv;ac];
        ce_cv=[ce_cv;ce];
    end
    endt=cputime;
    mvmn_time=endt-startt;

    % Get the mean performance metrics for all the folds
    mvmn_mean_ac_cv=mean(ac_cv);
    mvmn_mean_ce_cv=mean(ce_cv);

    mvmn_mean_ac_cv;
    mvmn_mean_ce_cv;
    
    %Save the results. 
    num_folds=[num_folds;f];
    best_dist=[dist;cellstr(distributions)];
    cross_entropy=[cross_entropy;mvmn_mean_ce_cv];
    accuracy=[accuracy;mvmn_mean_ac_cv];
    time=[time;mvmn_time];
    best_kernel=[best_kernel;cellstr('NA')];
        
end


%% 
num_folds=array2table(num_folds);
dist=array2table(dist);
cross_entropy=array2table(cross_entropy);
accuracy=array2table(accuracy);
time=array2table(time);
best_kernel=array2table(best_kernel);



multinomial_results=[num_folds dist cross_entropy accuracy time]



%% 2) Cross Validation with 'kernel' distribution of variables
% set out all the variables
ac_cv=[];
ce_cv=[];
target_all=[];
predictions_all=[];
prior = [0.6999 0.2227 0.0398 0.0376];
class_names={'unacc','acc','good','vgood'};
distributions='kernel';
w=BestWidth;
ktype=BestKernelType;
num_folds = 10;
training_err = zeros(num_folds,1);

rng(1);
c = cvpartition(nb_ms.acceptability,'KFold',num_folds);
startt=cputime;
for fold = 1:10
    %get the train and validation sets
     train = nb_ms(c.training(fold), :);   
     val = nb_ms(c.test(fold), :);
     
     %split them into X and Y arrays
     Xtr=table2array(train(:,1:6));
     Ytr=table2array(train(:,7));

     Xv=table2array(val(:,1:6));
     Yv=table2array(val(:,7));
     
     % Train a model
        Mdl = fitcnb(Xtr,Ytr,...
            'ClassNames',class_names,...
            'Prior',prior,...
            'DistributionNames',distributions,...
            'Width',w,...
            'Kernel',ktype);
     
    % Predict Results
    [label,Posterior,Cost] = predict(Mdl,Xv);
    
    % Store the results against their targets
    target_all=[target_all; Yv];
    predictions_all=[predictions_all;label];
    
    % Evaluate Model
    [ac, ce]=performance_metrics(Mdl, Xv,Yv, Posterior);
    ac_cv=[ac_cv;ac];
    ce_cv=[ce_cv;ce];
end
endt=cputime;
kernel_time=endt-startt;
%% Get the mean performance metrics for all the folds
kernel_mean_ac_cv=mean(ac_cv);
kernel_mean_ce_cv=mean(ce_cv);

kernel_mean_ac_cv;
kernel_mean_ce_cv;


%% It seems that the NB using a box kernel distribution is bettern than 
%one using multivariate multinomial distribution, both in terms of 
% accuracy and cross-entropy, and a bit more computationally heavy than mvmn.  


%% Confusion Matrix to see which classes suffer most from the innacuracies. 
predictions_all=categorical(predictions_all,avalues,'Ordinal',true);
C = confusionmat(target_all,predictions_all);
C


%% Histograms
histogram(table2array(nb_ms(:,7)));

%% Train the model on the entire train set and make final predictions on the test set. 
% Read the numerical test dataset for Naive Bayes Model Selection
test_nb=readtable('testNum.csv');

% specify that the last column is ordinal categorical data
avalues={'unacc','acc','good','vgood'};
test_nb.acceptability=categorical(test_nb.acceptability,avalues,'Ordinal',true);

%split them into X and Y arrays
Xtr=table2array(nb_ms(:,1:6));
Ytr=table2array(nb_ms(:,7));

Xv=table2array(test_nb(:,1:6));
Yv=table2array(test_nb(:,7));

%Train the model with kernel parameters
Mdl = fitcnb(Xtr,Ytr,...
            'ClassNames',class_names,...
            'Prior',prior,...
            'DistributionNames',distributions,...
            'Width',w,...
            'Kernel',ktype);
  
% Predict Results
[label,Posterior,Cost] = predict(Mdl,Xv);
    
% Evaluate Model
[ac_final, ce_final]=performance_metrics(Mdl, Xv,Yv, Posterior);


%% save the results of predictions
predictions=array2table([Yv label]);
VarNames={'target','predictions'};
predictions.Properties.VariableNames = VarNames;
writetable(predictions,'final_results_nb.csv');


